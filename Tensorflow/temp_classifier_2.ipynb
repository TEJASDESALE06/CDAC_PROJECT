
ğŸŒ¡ï¸ Temperature Classification using DHT22 Classes: Cold â€“ Warm â€“ Hot 1ï¸âƒ£ Problem Definition (Very Important) Sensor

DHT22 temperature sensor

Output: Temperature in Â°C (continuous value)

Goal

Convert a continuous temperature into discrete classes:Cold

Warm

Hot

ğŸ‘‰ This is a CLASSIFICATION problem, not regression.

2ï¸âƒ£ Define the Classes (Domain Knowledge)

You must define ranges first (this is important for teaching).

Example class definition Class Temperature Range (Â°C) Cold < 20 Warm 20 â€“ 30 Hot > 30

ğŸ“Œ You can adjust these ranges based on location.

3ï¸âƒ£ Dataset Creation (Simple & Realistic) Example dataset format Temperature (Â°C) Label 16.5 Cold 22.0 Warm 28.5 Warm 32.0 Hot 35.5 Hot

Python label encoding

def label_temperature_norm(temp_norm):
    temp = temp_norm * 50.0  # convert back to Â°C
    if temp < 20:
        return 0   # Cold
    elif temp <= 30:
        return 1   # Warm
    else:
        return 2   # Hot
Class mapping:

class_names = ["Cold", "Warm", "Hot"]
Create Training Data (Synthetic or Real)

import numpy as np
import sklearn

# Generate synthetic temperature data
temps = np.random.uniform(10, 40, 600)
temps_norm = temps / 50.0

labels = np.array([label_temperature_norm(t) for t in temps_norm])

X = temps_norm.reshape(-1, 1)
y = labels
# Normalize (DHT22 max range â‰ˆ 50Â°C)
X = X / 50.0
âš ï¸ Golden Rule:

Same normalization must be applied on STM32 / ESP32. 5ï¸âƒ£ Split Data (Train / Test)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
6ï¸âƒ£ Build Embedded-Friendly Model

Minimal neural network (perfect for MCUs):

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Dense(16, activation='relu', input_shape=(1,)),
    tf.keras.layers.Dense(8, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])


model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()
Model: "sequential_1"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ dense_2 (Dense)                 â”‚ (None, 16)             â”‚            32 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (Dense)                 â”‚ (None, 8)              â”‚           136 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_4 (Dense)                 â”‚ (None, 3)              â”‚            27 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 195 (780.00 B)
 Trainable params: 195 (780.00 B)
 Non-trainable params: 0 (0.00 B)
7ï¸âƒ£ Train the Model

history = model.fit(
    X_train, y_train,
    epochs=150,
    batch_size=16,
    validation_split=0.1,
    verbose=1
)
Epoch 1/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9222 - loss: 0.5159 - val_accuracy: 0.9000 - val_loss: 0.5148
Epoch 2/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9194 - loss: 0.5063 - val_accuracy: 0.9250 - val_loss: 0.5031
Epoch 3/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9250 - loss: 0.5028 - val_accuracy: 0.9250 - val_loss: 0.5138
Epoch 4/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9167 - loss: 0.5021 - val_accuracy: 0.9250 - val_loss: 0.5108
Epoch 5/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9444 - loss: 0.4915 - val_accuracy: 0.9250 - val_loss: 0.5074
Epoch 6/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9389 - loss: 0.4859 - val_accuracy: 0.9750 - val_loss: 0.4904
Epoch 7/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9361 - loss: 0.4813 - val_accuracy: 0.9250 - val_loss: 0.4947
Epoch 8/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9417 - loss: 0.4795 - val_accuracy: 0.9250 - val_loss: 0.4832
Epoch 9/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9500 - loss: 0.4717 - val_accuracy: 0.9750 - val_loss: 0.4784
Epoch 10/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9500 - loss: 0.4670 - val_accuracy: 0.9500 - val_loss: 0.4688
Epoch 11/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9361 - loss: 0.4621 - val_accuracy: 0.9750 - val_loss: 0.4685
Epoch 12/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9278 - loss: 0.4621 - val_accuracy: 0.9750 - val_loss: 0.4646
Epoch 13/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9278 - loss: 0.4568 - val_accuracy: 1.0000 - val_loss: 0.4617
Epoch 14/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9528 - loss: 0.4479 - val_accuracy: 0.9250 - val_loss: 0.4659
Epoch 15/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9500 - loss: 0.4449 - val_accuracy: 1.0000 - val_loss: 0.4526
Epoch 16/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9250 - loss: 0.4414 - val_accuracy: 0.9250 - val_loss: 0.4574
Epoch 17/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9583 - loss: 0.4370 - val_accuracy: 0.9250 - val_loss: 0.4508
Epoch 18/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9583 - loss: 0.4320 - val_accuracy: 0.9250 - val_loss: 0.4621
Epoch 19/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9417 - loss: 0.4349 - val_accuracy: 0.9250 - val_loss: 0.4494
Epoch 20/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9361 - loss: 0.4291 - val_accuracy: 0.9750 - val_loss: 0.4309
Epoch 21/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9361 - loss: 0.4240 - val_accuracy: 0.9000 - val_loss: 0.4269
Epoch 22/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9333 - loss: 0.4161 - val_accuracy: 0.9250 - val_loss: 0.4454
Epoch 23/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9583 - loss: 0.4118 - val_accuracy: 1.0000 - val_loss: 0.4241
Epoch 24/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9667 - loss: 0.4067 - val_accuracy: 0.9250 - val_loss: 0.4263
Epoch 25/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9472 - loss: 0.4045 - val_accuracy: 1.0000 - val_loss: 0.4179
Epoch 26/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9694 - loss: 0.4009 - val_accuracy: 0.9250 - val_loss: 0.4329
Epoch 27/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9694 - loss: 0.3952 - val_accuracy: 1.0000 - val_loss: 0.4140
Epoch 28/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9611 - loss: 0.3912 - val_accuracy: 1.0000 - val_loss: 0.4098
Epoch 29/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9639 - loss: 0.3893 - val_accuracy: 0.9250 - val_loss: 0.4116
Epoch 30/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9611 - loss: 0.3857 - val_accuracy: 0.9750 - val_loss: 0.3987
Epoch 31/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9611 - loss: 0.3835 - val_accuracy: 1.0000 - val_loss: 0.3985
Epoch 32/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9472 - loss: 0.3830 - val_accuracy: 1.0000 - val_loss: 0.3963
Epoch 33/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9639 - loss: 0.3761 - val_accuracy: 1.0000 - val_loss: 0.3973
Epoch 34/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9667 - loss: 0.3720 - val_accuracy: 0.9250 - val_loss: 0.4001
Epoch 35/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9694 - loss: 0.3689 - val_accuracy: 0.9250 - val_loss: 0.3958
Epoch 36/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9750 - loss: 0.3645 - val_accuracy: 1.0000 - val_loss: 0.3816
Epoch 37/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9694 - loss: 0.3617 - val_accuracy: 1.0000 - val_loss: 0.3821
Epoch 38/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9667 - loss: 0.3594 - val_accuracy: 1.0000 - val_loss: 0.3864
Epoch 39/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9694 - loss: 0.3581 - val_accuracy: 0.9250 - val_loss: 0.3916
Epoch 40/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9750 - loss: 0.3544 - val_accuracy: 0.9250 - val_loss: 0.3883
Epoch 41/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9722 - loss: 0.3489 - val_accuracy: 0.9250 - val_loss: 0.3831
Epoch 42/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9583 - loss: 0.3524 - val_accuracy: 1.0000 - val_loss: 0.3722
Epoch 43/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9694 - loss: 0.3438 - val_accuracy: 1.0000 - val_loss: 0.3644
Epoch 44/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9667 - loss: 0.3448 - val_accuracy: 1.0000 - val_loss: 0.3680
Epoch 45/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9583 - loss: 0.3364 - val_accuracy: 0.9000 - val_loss: 0.3868
Epoch 46/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9611 - loss: 0.3389 - val_accuracy: 0.9250 - val_loss: 0.3677
Epoch 47/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9806 - loss: 0.3349 - val_accuracy: 1.0000 - val_loss: 0.3542
Epoch 48/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9722 - loss: 0.3309 - val_accuracy: 1.0000 - val_loss: 0.3510
Epoch 49/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9500 - loss: 0.3358 - val_accuracy: 1.0000 - val_loss: 0.3497
Epoch 50/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9806 - loss: 0.3237 - val_accuracy: 0.9750 - val_loss: 0.3472
Epoch 51/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9639 - loss: 0.3215 - val_accuracy: 0.9500 - val_loss: 0.3461
Epoch 52/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9583 - loss: 0.3224 - val_accuracy: 0.9750 - val_loss: 0.3421
Epoch 53/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9750 - loss: 0.3187 - val_accuracy: 1.0000 - val_loss: 0.3422
Epoch 54/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9778 - loss: 0.3154 - val_accuracy: 1.0000 - val_loss: 0.3425
Epoch 55/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9833 - loss: 0.3124 - val_accuracy: 1.0000 - val_loss: 0.3396
Epoch 56/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9639 - loss: 0.3119 - val_accuracy: 1.0000 - val_loss: 0.3449
Epoch 57/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9667 - loss: 0.3101 - val_accuracy: 1.0000 - val_loss: 0.3327
Epoch 58/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9722 - loss: 0.3051 - val_accuracy: 1.0000 - val_loss: 0.3292
Epoch 59/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9778 - loss: 0.3013 - val_accuracy: 1.0000 - val_loss: 0.3391
Epoch 60/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9667 - loss: 0.3016 - val_accuracy: 0.9000 - val_loss: 0.3423
Epoch 61/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9750 - loss: 0.2997 - val_accuracy: 1.0000 - val_loss: 0.3261
Epoch 62/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9639 - loss: 0.2981 - val_accuracy: 0.9750 - val_loss: 0.3217
Epoch 63/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9694 - loss: 0.2938 - val_accuracy: 0.9750 - val_loss: 0.3194
Epoch 64/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9806 - loss: 0.2891 - val_accuracy: 1.0000 - val_loss: 0.3319
Epoch 65/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9667 - loss: 0.2918 - val_accuracy: 1.0000 - val_loss: 0.3296
Epoch 66/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9694 - loss: 0.2861 - val_accuracy: 1.0000 - val_loss: 0.3181
Epoch 67/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9806 - loss: 0.2842 - val_accuracy: 1.0000 - val_loss: 0.3121
Epoch 68/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9889 - loss: 0.2812 - val_accuracy: 1.0000 - val_loss: 0.3251
Epoch 69/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9694 - loss: 0.2865 - val_accuracy: 0.9500 - val_loss: 0.3100
Epoch 70/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9611 - loss: 0.2857 - val_accuracy: 1.0000 - val_loss: 0.3170
Epoch 71/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9556 - loss: 0.2833 - val_accuracy: 1.0000 - val_loss: 0.3165
Epoch 72/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9833 - loss: 0.2735 - val_accuracy: 1.0000 - val_loss: 0.3054
Epoch 73/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9722 - loss: 0.2735 - val_accuracy: 1.0000 - val_loss: 0.3049
Epoch 74/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9583 - loss: 0.2709 - val_accuracy: 0.9750 - val_loss: 0.2996
Epoch 75/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9833 - loss: 0.2683 - val_accuracy: 1.0000 - val_loss: 0.3000
Epoch 76/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9833 - loss: 0.2676 - val_accuracy: 0.9750 - val_loss: 0.2967
Epoch 77/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9556 - loss: 0.2735 - val_accuracy: 0.9750 - val_loss: 0.2935
Epoch 78/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9833 - loss: 0.2640 - val_accuracy: 1.0000 - val_loss: 0.3066
Epoch 79/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9806 - loss: 0.2690 - val_accuracy: 1.0000 - val_loss: 0.3041
Epoch 80/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9722 - loss: 0.2638 - val_accuracy: 1.0000 - val_loss: 0.2915
Epoch 81/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9861 - loss: 0.2569 - val_accuracy: 1.0000 - val_loss: 0.2890
Epoch 82/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9889 - loss: 0.2552 - val_accuracy: 1.0000 - val_loss: 0.2897
Epoch 83/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9778 - loss: 0.2554 - val_accuracy: 0.9250 - val_loss: 0.2879
Epoch 84/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9417 - loss: 0.2659 - val_accuracy: 0.9250 - val_loss: 0.2888
Epoch 85/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9778 - loss: 0.2543 - val_accuracy: 0.9750 - val_loss: 0.2804
Epoch 86/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9444 - loss: 0.2580 - val_accuracy: 0.8750 - val_loss: 0.2988
Epoch 87/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9194 - loss: 0.2690 - val_accuracy: 0.9250 - val_loss: 0.2845
Epoch 88/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9694 - loss: 0.2465 - val_accuracy: 1.0000 - val_loss: 0.2793
Epoch 89/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9889 - loss: 0.2444 - val_accuracy: 1.0000 - val_loss: 0.2774
Epoch 90/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9778 - loss: 0.2465 - val_accuracy: 0.9750 - val_loss: 0.2745
Epoch 91/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9611 - loss: 0.2446 - val_accuracy: 1.0000 - val_loss: 0.2733
Epoch 92/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9778 - loss: 0.2434 - val_accuracy: 0.9750 - val_loss: 0.2724
Epoch 93/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9639 - loss: 0.2408 - val_accuracy: 0.9250 - val_loss: 0.2774
Epoch 94/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9833 - loss: 0.2411 - val_accuracy: 1.0000 - val_loss: 0.2702
Epoch 95/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9611 - loss: 0.2375 - val_accuracy: 0.9750 - val_loss: 0.2690
Epoch 96/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9750 - loss: 0.2382 - val_accuracy: 0.9750 - val_loss: 0.2666
Epoch 97/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9722 - loss: 0.2350 - val_accuracy: 1.0000 - val_loss: 0.2747
Epoch 98/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9806 - loss: 0.2378 - val_accuracy: 0.9750 - val_loss: 0.2637
Epoch 99/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9667 - loss: 0.2359 - val_accuracy: 1.0000 - val_loss: 0.2628
Epoch 100/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9917 - loss: 0.2284 - val_accuracy: 1.0000 - val_loss: 0.2684
Epoch 101/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9722 - loss: 0.2283 - val_accuracy: 1.0000 - val_loss: 0.2620
Epoch 102/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9778 - loss: 0.2275 - val_accuracy: 1.0000 - val_loss: 0.2694
Epoch 103/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9778 - loss: 0.2270 - val_accuracy: 0.9250 - val_loss: 0.2619
Epoch 104/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9833 - loss: 0.2226 - val_accuracy: 1.0000 - val_loss: 0.2630
Epoch 105/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9750 - loss: 0.2228 - val_accuracy: 0.9750 - val_loss: 0.2703
Epoch 106/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9778 - loss: 0.2231 - val_accuracy: 0.9750 - val_loss: 0.2679
Epoch 107/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.9694 - loss: 0.2255 - val_accuracy: 1.0000 - val_loss: 0.2636
Epoch 108/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9750 - loss: 0.2213 - val_accuracy: 1.0000 - val_loss: 0.2639
Epoch 109/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9750 - loss: 0.2157 - val_accuracy: 0.9750 - val_loss: 0.2539
Epoch 110/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9889 - loss: 0.2172 - val_accuracy: 0.9750 - val_loss: 0.2485
Epoch 111/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9778 - loss: 0.2161 - val_accuracy: 1.0000 - val_loss: 0.2526
Epoch 112/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9861 - loss: 0.2133 - val_accuracy: 0.9750 - val_loss: 0.2479
Epoch 113/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9722 - loss: 0.2153 - val_accuracy: 1.0000 - val_loss: 0.2514
Epoch 114/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9833 - loss: 0.2131 - val_accuracy: 1.0000 - val_loss: 0.2490
Epoch 115/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9917 - loss: 0.2113 - val_accuracy: 1.0000 - val_loss: 0.2444
Epoch 116/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9750 - loss: 0.2119 - val_accuracy: 1.0000 - val_loss: 0.2453
Epoch 117/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9750 - loss: 0.2083 - val_accuracy: 0.9750 - val_loss: 0.2420
Epoch 118/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9917 - loss: 0.2062 - val_accuracy: 1.0000 - val_loss: 0.2421
Epoch 119/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9750 - loss: 0.2114 - val_accuracy: 1.0000 - val_loss: 0.2386
Epoch 120/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9806 - loss: 0.2041 - val_accuracy: 0.9000 - val_loss: 0.2669
Epoch 121/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9722 - loss: 0.2103 - val_accuracy: 1.0000 - val_loss: 0.2436
Epoch 122/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9750 - loss: 0.2100 - val_accuracy: 1.0000 - val_loss: 0.2462
Epoch 123/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9528 - loss: 0.2135 - val_accuracy: 1.0000 - val_loss: 0.2382
Epoch 124/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9917 - loss: 0.2022 - val_accuracy: 1.0000 - val_loss: 0.2357
Epoch 125/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9833 - loss: 0.2009 - val_accuracy: 0.9750 - val_loss: 0.2486
Epoch 126/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9722 - loss: 0.1999 - val_accuracy: 1.0000 - val_loss: 0.2354
Epoch 127/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9667 - loss: 0.2035 - val_accuracy: 1.0000 - val_loss: 0.2334
Epoch 128/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9750 - loss: 0.1989 - val_accuracy: 1.0000 - val_loss: 0.2397
Epoch 129/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9806 - loss: 0.1987 - val_accuracy: 0.9750 - val_loss: 0.2463
Epoch 130/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9722 - loss: 0.2015 - val_accuracy: 0.9000 - val_loss: 0.2754
Epoch 131/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9833 - loss: 0.1958 - val_accuracy: 1.0000 - val_loss: 0.2357
Epoch 132/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9639 - loss: 0.2006 - val_accuracy: 0.9000 - val_loss: 0.2614
Epoch 133/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9750 - loss: 0.1956 - val_accuracy: 1.0000 - val_loss: 0.2298
Epoch 134/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9889 - loss: 0.1920 - val_accuracy: 0.9750 - val_loss: 0.2266
Epoch 135/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9750 - loss: 0.1957 - val_accuracy: 1.0000 - val_loss: 0.2229
Epoch 136/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9806 - loss: 0.1911 - val_accuracy: 0.9500 - val_loss: 0.2296
Epoch 137/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9861 - loss: 0.1938 - val_accuracy: 1.0000 - val_loss: 0.2214
Epoch 138/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9722 - loss: 0.1899 - val_accuracy: 1.0000 - val_loss: 0.2207
Epoch 139/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9722 - loss: 0.1918 - val_accuracy: 1.0000 - val_loss: 0.2231
Epoch 140/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9861 - loss: 0.1885 - val_accuracy: 1.0000 - val_loss: 0.2235
Epoch 141/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9861 - loss: 0.1855 - val_accuracy: 1.0000 - val_loss: 0.2172
Epoch 142/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9889 - loss: 0.1844 - val_accuracy: 1.0000 - val_loss: 0.2171
Epoch 143/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9861 - loss: 0.1824 - val_accuracy: 1.0000 - val_loss: 0.2268
Epoch 144/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9639 - loss: 0.1862 - val_accuracy: 0.9750 - val_loss: 0.2368
Epoch 145/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9722 - loss: 0.1875 - val_accuracy: 1.0000 - val_loss: 0.2215
Epoch 146/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9806 - loss: 0.1840 - val_accuracy: 0.9500 - val_loss: 0.2217
Epoch 147/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9667 - loss: 0.1852 - val_accuracy: 1.0000 - val_loss: 0.2133
Epoch 148/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9889 - loss: 0.1805 - val_accuracy: 1.0000 - val_loss: 0.2111
Epoch 149/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 5ms/step - accuracy: 0.9639 - loss: 0.1835 - val_accuracy: 0.9750 - val_loss: 0.2271
Epoch 150/150
23/23 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9833 - loss: 0.1805 - val_accuracy: 1.0000 - val_loss: 0.2132
8ï¸âƒ£ Evaluate the Model

loss, acc = model.evaluate(X_test, y_test)
print("Test Accuracy:", acc)
4/4 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 8ms/step - accuracy: 1.0000 - loss: 0.2134 
Test Accuracy: 1.0
9ï¸âƒ£ Test with Known Temperatures (Demo Cell)

test_temps = np.array([15, 25, 35]).reshape(-1, 1)
test_temps_norm = test_temps / 50.0

pred = model.predict(test_temps_norm)
pred_classes = np.argmax(pred, axis=1)

for t, c in zip(test_temps.flatten(), pred_classes):
    print(f"{t} Â°C â†’ {class_names[c]}")
1/1 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 48ms/step
15 Â°C â†’ Hot
25 Â°C â†’ Hot
35 Â°C â†’ Hot
unique, counts = np.unique(y, return_counts=True)
dict(zip(unique, counts))
{np.int64(0): np.int64(175),
 np.int64(1): np.int64(163),
 np.int64(2): np.int64(162)}
ğŸ”Ÿ Confidence Interpretation (Very Important)

confidence = np.max(pred, axis=1)

for t, conf in zip(test_temps.flatten(), confidence):
    print(f"Confidence: {conf:.2f}")
Confidence: 1.00
Confidence: 1.00
Confidence: 1.00
pred = model.predict(test_temps_norm)
pred_class = np.argmax(pred, axis=1)
confidence = np.max(pred, axis=1)

for t, c, conf in zip(test_temps.flatten(), pred_class, confidence):
    if conf < 0.7:
        print(f"{t} Â°C â†’ Uncertain")
    else:
        print(f"{t} Â°C â†’ {class_names[c]} ({conf:.2f})")
1/1 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 55ms/step
15 Â°C â†’ Hot (1.00)
25 Â°C â†’ Hot (1.00)
35 Â°C â†’ Hot (1.00)
1ï¸âƒ£1ï¸âƒ£ Convert to TensorFlow Lite (For Embedded)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

tflite_model = converter.convert()

with open("dht22_temp_classifier.tflite", "wb") as f:
    f.write(tflite_model)

print("TFLite model size:", len(tflite_model), "bytes")
