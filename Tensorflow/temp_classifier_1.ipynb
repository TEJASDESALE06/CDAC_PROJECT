
ğŸŒ¡ï¸ Temperature Classification using DHT22 Classes: Cold â€“ Warm â€“ Hot 1ï¸âƒ£ Problem Definition (Very Important) Sensor

DHT22 temperature sensor

Output: Temperature in Â°C (continuous value)

Goal

Convert a continuous temperature into discrete classes:Cold

Warm

Hot

ğŸ‘‰ This is a CLASSIFICATION problem, not regression.

2ï¸âƒ£ Define the Classes (Domain Knowledge)

You must define ranges first (this is important for teaching).

Example class definition Class Temperature Range (Â°C) Cold < 20 Warm 20 â€“ 30 Hot > 30

ğŸ“Œ You can adjust these ranges based on location.

3ï¸âƒ£ Dataset Creation (Simple & Realistic) Example dataset format Temperature (Â°C) Label 16.5 Cold 22.0 Warm 28.5 Warm 32.0 Hot 35.5 Hot

Python label encoding

def label_temperature_norm(temp_norm):
    temp = temp_norm * 50.0  # convert back to Â°C
    if temp < 20:
        return 0   # Cold
    elif temp <= 30:
        return 1   # Warm
    else:
        return 2   # Hot
Class mapping:

class_names = ["Cold", "Warm", "Hot"]
Create Training Data (Synthetic or Real)

import numpy as np
import sklearn

# Generate synthetic temperature data
temps = np.random.uniform(10, 40, 300)
temps_norm = temps / 50.0

labels = np.array([label_temperature_norm(t) for t in temps_norm])

X = temps_norm.reshape(-1, 1)
y = labels
# Normalize (DHT22 max range â‰ˆ 50Â°C)
X = X / 50.0
âš ï¸ Golden Rule:

Same normalization must be applied on STM32 / ESP32. 5ï¸âƒ£ Split Data (Train / Test)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
6ï¸âƒ£ Build Embedded-Friendly Model

Minimal neural network (perfect for MCUs):

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Dense(16, activation='relu', input_shape=(1,)),
    tf.keras.layers.Dense(8, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])


model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()
/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential_1"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ dense_3 (Dense)                 â”‚ (None, 16)             â”‚            32 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_4 (Dense)                 â”‚ (None, 8)              â”‚           136 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_5 (Dense)                 â”‚ (None, 3)              â”‚            27 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 195 (780.00 B)
 Trainable params: 195 (780.00 B)
 Non-trainable params: 0 (0.00 B)
7ï¸âƒ£ Train the Model

history = model.fit(
    X_train, y_train,
    epochs=150,
    batch_size=16,
    validation_split=0.1,
    verbose=1
)
Epoch 1/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 18ms/step - accuracy: 0.3089 - loss: 1.0998 - val_accuracy: 0.3750 - val_loss: 1.0988
Epoch 2/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.3180 - loss: 1.0992 - val_accuracy: 0.3333 - val_loss: 1.0984
Epoch 3/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3720 - loss: 1.0983 - val_accuracy: 0.3333 - val_loss: 1.0983
Epoch 4/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3327 - loss: 1.0987 - val_accuracy: 0.3333 - val_loss: 1.0984
Epoch 5/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3799 - loss: 1.0982 - val_accuracy: 0.3333 - val_loss: 1.0986
Epoch 6/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3379 - loss: 1.0984 - val_accuracy: 0.3333 - val_loss: 1.0985
Epoch 7/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3312 - loss: 1.0984 - val_accuracy: 0.3333 - val_loss: 1.0983
Epoch 8/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3911 - loss: 1.0976 - val_accuracy: 0.3333 - val_loss: 1.0984
Epoch 9/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3532 - loss: 1.0980 - val_accuracy: 0.3333 - val_loss: 1.0983
Epoch 10/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3676 - loss: 1.0976 - val_accuracy: 0.3333 - val_loss: 1.0979
Epoch 11/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.3495 - loss: 1.0981 - val_accuracy: 0.3333 - val_loss: 1.0983
Epoch 12/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3264 - loss: 1.0983 - val_accuracy: 0.3333 - val_loss: 1.0981
Epoch 13/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3295 - loss: 1.0983 - val_accuracy: 0.3333 - val_loss: 1.0981
Epoch 14/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3286 - loss: 1.0983 - val_accuracy: 0.3333 - val_loss: 1.0982
Epoch 15/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3449 - loss: 1.0978 - val_accuracy: 0.3333 - val_loss: 1.0981
Epoch 16/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3595 - loss: 1.0971 - val_accuracy: 0.3333 - val_loss: 1.0979
Epoch 17/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3123 - loss: 1.0985 - val_accuracy: 0.3333 - val_loss: 1.0979
Epoch 18/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3726 - loss: 1.0967 - val_accuracy: 0.3333 - val_loss: 1.0973
Epoch 19/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3597 - loss: 1.0971 - val_accuracy: 0.3333 - val_loss: 1.0977
Epoch 20/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.3426 - loss: 1.0972 - val_accuracy: 0.3333 - val_loss: 1.0972
Epoch 21/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3590 - loss: 1.0965 - val_accuracy: 0.3333 - val_loss: 1.0972
Epoch 22/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3012 - loss: 1.0983 - val_accuracy: 0.3333 - val_loss: 1.0966
Epoch 23/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3614 - loss: 1.0959 - val_accuracy: 0.3333 - val_loss: 1.0964
Epoch 24/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3736 - loss: 1.0952 - val_accuracy: 0.3333 - val_loss: 1.0962
Epoch 25/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3351 - loss: 1.0967 - val_accuracy: 0.3333 - val_loss: 1.0963
Epoch 26/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3262 - loss: 1.0965 - val_accuracy: 0.3333 - val_loss: 1.0957
Epoch 27/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3680 - loss: 1.0945 - val_accuracy: 0.3333 - val_loss: 1.0955
Epoch 28/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3272 - loss: 1.0965 - val_accuracy: 0.3333 - val_loss: 1.0949
Epoch 29/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 9ms/step - accuracy: 0.3768 - loss: 1.0943 - val_accuracy: 0.3333 - val_loss: 1.0945
Epoch 30/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3910 - loss: 1.0926 - val_accuracy: 0.3333 - val_loss: 1.0938
Epoch 31/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3832 - loss: 1.0934 - val_accuracy: 0.3333 - val_loss: 1.0945
Epoch 32/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3443 - loss: 1.0944 - val_accuracy: 0.3333 - val_loss: 1.0941
Epoch 33/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3507 - loss: 1.0932 - val_accuracy: 0.3333 - val_loss: 1.0922
Epoch 34/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.2991 - loss: 1.0953 - val_accuracy: 0.3333 - val_loss: 1.0930
Epoch 35/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3562 - loss: 1.0926 - val_accuracy: 0.3333 - val_loss: 1.0927
Epoch 36/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3958 - loss: 1.0902 - val_accuracy: 0.3333 - val_loss: 1.0920
Epoch 37/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3483 - loss: 1.0928 - val_accuracy: 0.3333 - val_loss: 1.0909
Epoch 38/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.3954 - loss: 1.0896 - val_accuracy: 0.4167 - val_loss: 1.0886
Epoch 39/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.4112 - loss: 1.0931 - val_accuracy: 0.3333 - val_loss: 1.0906
Epoch 40/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3389 - loss: 1.0909 - val_accuracy: 0.3333 - val_loss: 1.0883
Epoch 41/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3705 - loss: 1.0905 - val_accuracy: 0.3333 - val_loss: 1.0894
Epoch 42/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3574 - loss: 1.0887 - val_accuracy: 0.3333 - val_loss: 1.0897
Epoch 43/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3144 - loss: 1.0901 - val_accuracy: 0.3333 - val_loss: 1.0887
Epoch 44/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3808 - loss: 1.0868 - val_accuracy: 0.3333 - val_loss: 1.0877
Epoch 45/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.4235 - loss: 1.0848 - val_accuracy: 0.3333 - val_loss: 1.0875
Epoch 46/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3469 - loss: 1.0878 - val_accuracy: 0.3333 - val_loss: 1.0858
Epoch 47/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.4283 - loss: 1.0850 - val_accuracy: 0.5833 - val_loss: 1.0835
Epoch 48/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.6200 - loss: 1.0835 - val_accuracy: 0.7083 - val_loss: 1.0823
Epoch 49/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5667 - loss: 1.0838 - val_accuracy: 0.4167 - val_loss: 1.0819
Epoch 50/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3821 - loss: 1.0831 - val_accuracy: 0.6250 - val_loss: 1.0797
Epoch 51/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5379 - loss: 1.0833 - val_accuracy: 0.5833 - val_loss: 1.0789
Epoch 52/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6612 - loss: 1.0787 - val_accuracy: 0.5000 - val_loss: 1.0782
Epoch 53/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5175 - loss: 1.0766 - val_accuracy: 0.5000 - val_loss: 1.0767
Epoch 54/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5052 - loss: 1.0758 - val_accuracy: 0.6667 - val_loss: 1.0749
Epoch 55/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5403 - loss: 1.0759 - val_accuracy: 0.6667 - val_loss: 1.0737
Epoch 56/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5761 - loss: 1.0746 - val_accuracy: 0.7083 - val_loss: 1.0716
Epoch 57/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 8ms/step - accuracy: 0.6049 - loss: 1.0735 - val_accuracy: 0.7083 - val_loss: 1.0699
Epoch 58/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6117 - loss: 1.0700 - val_accuracy: 0.7083 - val_loss: 1.0678
Epoch 59/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.5562 - loss: 1.0699 - val_accuracy: 0.4583 - val_loss: 1.0652
Epoch 60/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3619 - loss: 1.0704 - val_accuracy: 0.4167 - val_loss: 1.0629
Epoch 61/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.4745 - loss: 1.0619 - val_accuracy: 0.7083 - val_loss: 1.0632
Epoch 62/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6639 - loss: 1.0614 - val_accuracy: 0.6250 - val_loss: 1.0602
Epoch 63/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.5929 - loss: 1.0626 - val_accuracy: 0.4167 - val_loss: 1.0569
Epoch 64/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.4010 - loss: 1.0610 - val_accuracy: 0.4583 - val_loss: 1.0550
Epoch 65/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.5749 - loss: 1.0527 - val_accuracy: 0.4583 - val_loss: 1.0536
Epoch 66/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 8ms/step - accuracy: 0.5209 - loss: 1.0504 - val_accuracy: 0.4583 - val_loss: 1.0503
Epoch 67/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5957 - loss: 1.0496 - val_accuracy: 0.4167 - val_loss: 1.0473
Epoch 68/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.3952 - loss: 1.0456 - val_accuracy: 0.5417 - val_loss: 1.0470
Epoch 69/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7079 - loss: 1.0525 - val_accuracy: 0.4167 - val_loss: 1.0424
Epoch 70/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.3657 - loss: 1.0445 - val_accuracy: 0.6250 - val_loss: 1.0428
Epoch 71/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6590 - loss: 1.0400 - val_accuracy: 0.5000 - val_loss: 1.0378
Epoch 72/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5634 - loss: 1.0400 - val_accuracy: 0.5000 - val_loss: 1.0352
Epoch 73/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.6160 - loss: 1.0425 - val_accuracy: 0.4167 - val_loss: 1.0319
Epoch 74/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.3726 - loss: 1.0527 - val_accuracy: 0.4167 - val_loss: 1.0292
Epoch 75/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 8ms/step - accuracy: 0.3534 - loss: 1.0380 - val_accuracy: 0.5833 - val_loss: 1.0291
Epoch 76/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7461 - loss: 1.0320 - val_accuracy: 0.3750 - val_loss: 1.0244
Epoch 77/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.4085 - loss: 1.0275 - val_accuracy: 0.5833 - val_loss: 1.0234
Epoch 78/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.5643 - loss: 1.0203 - val_accuracy: 0.5417 - val_loss: 1.0184
Epoch 79/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7420 - loss: 1.0204 - val_accuracy: 0.4583 - val_loss: 1.0145
Epoch 80/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5131 - loss: 1.0187 - val_accuracy: 0.5833 - val_loss: 1.0130
Epoch 81/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6204 - loss: 1.0112 - val_accuracy: 0.5833 - val_loss: 1.0089
Epoch 82/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6724 - loss: 1.0097 - val_accuracy: 0.4583 - val_loss: 1.0048
Epoch 83/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - accuracy: 0.4099 - loss: 1.0147 - val_accuracy: 0.5833 - val_loss: 1.0027
Epoch 84/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - accuracy: 0.7041 - loss: 1.0072 - val_accuracy: 0.4167 - val_loss: 0.9992
Epoch 85/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 9ms/step - accuracy: 0.5114 - loss: 1.0109 - val_accuracy: 0.5000 - val_loss: 0.9945
Epoch 86/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 9ms/step - accuracy: 0.5818 - loss: 0.9951 - val_accuracy: 0.5833 - val_loss: 0.9920
Epoch 87/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 9ms/step - accuracy: 0.6128 - loss: 0.9905 - val_accuracy: 0.5833 - val_loss: 0.9883
Epoch 88/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 10ms/step - accuracy: 0.6324 - loss: 0.9824 - val_accuracy: 0.7083 - val_loss: 0.9899
Epoch 89/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 9ms/step - accuracy: 0.7883 - loss: 0.9887 - val_accuracy: 0.5417 - val_loss: 0.9810
Epoch 90/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - accuracy: 0.5701 - loss: 0.9886 - val_accuracy: 0.6250 - val_loss: 0.9798
Epoch 91/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 10ms/step - accuracy: 0.6826 - loss: 0.9774 - val_accuracy: 0.5417 - val_loss: 0.9739
Epoch 92/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 8ms/step - accuracy: 0.6877 - loss: 0.9742 - val_accuracy: 0.5417 - val_loss: 0.9696
Epoch 93/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6150 - loss: 0.9741 - val_accuracy: 0.6250 - val_loss: 0.9668
Epoch 94/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6877 - loss: 0.9713 - val_accuracy: 0.4583 - val_loss: 0.9661
Epoch 95/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.5664 - loss: 0.9605 - val_accuracy: 0.6667 - val_loss: 0.9616
Epoch 96/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5916 - loss: 0.9561 - val_accuracy: 0.7500 - val_loss: 0.9635
Epoch 97/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.8313 - loss: 0.9672 - val_accuracy: 0.4583 - val_loss: 0.9535
Epoch 98/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6023 - loss: 0.9745 - val_accuracy: 0.5417 - val_loss: 0.9485
Epoch 99/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.4829 - loss: 0.9565 - val_accuracy: 0.7083 - val_loss: 0.9470
Epoch 100/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7171 - loss: 0.9470 - val_accuracy: 0.5417 - val_loss: 0.9400
Epoch 101/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.5695 - loss: 0.9396 - val_accuracy: 0.7500 - val_loss: 0.9415
Epoch 102/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7710 - loss: 0.9423 - val_accuracy: 0.5417 - val_loss: 0.9336
Epoch 103/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.6321 - loss: 0.9313 - val_accuracy: 0.7083 - val_loss: 0.9303
Epoch 104/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6717 - loss: 0.9231 - val_accuracy: 0.7083 - val_loss: 0.9258
Epoch 105/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7414 - loss: 0.9219 - val_accuracy: 0.5833 - val_loss: 0.9209
Epoch 106/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6113 - loss: 0.9310 - val_accuracy: 0.5833 - val_loss: 0.9172
Epoch 107/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7213 - loss: 0.9097 - val_accuracy: 0.7083 - val_loss: 0.9136
Epoch 108/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7325 - loss: 0.9283 - val_accuracy: 0.5833 - val_loss: 0.9103
Epoch 109/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7324 - loss: 0.9240 - val_accuracy: 0.5833 - val_loss: 0.9080
Epoch 110/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6144 - loss: 0.9087 - val_accuracy: 0.7500 - val_loss: 0.9035
Epoch 111/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7726 - loss: 0.9001 - val_accuracy: 0.5833 - val_loss: 0.8978
Epoch 112/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.6468 - loss: 0.8878 - val_accuracy: 0.7083 - val_loss: 0.9027
Epoch 113/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7950 - loss: 0.8918 - val_accuracy: 0.5833 - val_loss: 0.8914
Epoch 114/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6753 - loss: 0.8915 - val_accuracy: 0.7083 - val_loss: 0.8865
Epoch 115/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7065 - loss: 0.8947 - val_accuracy: 0.7500 - val_loss: 0.8827
Epoch 116/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7312 - loss: 0.8860 - val_accuracy: 0.7083 - val_loss: 0.8785
Epoch 117/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7048 - loss: 0.8725 - val_accuracy: 0.7500 - val_loss: 0.8748
Epoch 118/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6732 - loss: 0.8702 - val_accuracy: 0.7500 - val_loss: 0.8720
Epoch 119/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7765 - loss: 0.8731 - val_accuracy: 0.5833 - val_loss: 0.8676
Epoch 120/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7238 - loss: 0.8485 - val_accuracy: 0.7500 - val_loss: 0.8663
Epoch 121/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 8ms/step - accuracy: 0.8232 - loss: 0.8809 - val_accuracy: 0.5833 - val_loss: 0.8640
Epoch 122/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6720 - loss: 0.8845 - val_accuracy: 0.7083 - val_loss: 0.8557
Epoch 123/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.6867 - loss: 0.8634 - val_accuracy: 0.7083 - val_loss: 0.8520
Epoch 124/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7582 - loss: 0.8409 - val_accuracy: 0.7500 - val_loss: 0.8485
Epoch 125/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7835 - loss: 0.8618 - val_accuracy: 0.5833 - val_loss: 0.8500
Epoch 126/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6275 - loss: 0.8468 - val_accuracy: 0.7083 - val_loss: 0.8492
Epoch 127/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7892 - loss: 0.8403 - val_accuracy: 0.5833 - val_loss: 0.8417
Epoch 128/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7780 - loss: 0.8264 - val_accuracy: 0.7500 - val_loss: 0.8329
Epoch 129/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7093 - loss: 0.8398 - val_accuracy: 0.7500 - val_loss: 0.8293
Epoch 130/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 8ms/step - accuracy: 0.7964 - loss: 0.8239 - val_accuracy: 0.7500 - val_loss: 0.8250
Epoch 131/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.8124 - loss: 0.8193 - val_accuracy: 0.7500 - val_loss: 0.8215
Epoch 132/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 10ms/step - accuracy: 0.7520 - loss: 0.8028 - val_accuracy: 0.7500 - val_loss: 0.8182
Epoch 133/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.8195 - loss: 0.8109 - val_accuracy: 0.7500 - val_loss: 0.8141
Epoch 134/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.8025 - loss: 0.8133 - val_accuracy: 0.7500 - val_loss: 0.8108
Epoch 135/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7686 - loss: 0.8146 - val_accuracy: 0.7500 - val_loss: 0.8078
Epoch 136/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6758 - loss: 0.8118 - val_accuracy: 0.7083 - val_loss: 0.8044
Epoch 137/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.8399 - loss: 0.7901 - val_accuracy: 0.7500 - val_loss: 0.8016
Epoch 138/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7695 - loss: 0.7916 - val_accuracy: 0.7500 - val_loss: 0.7961
Epoch 139/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7635 - loss: 0.7989 - val_accuracy: 0.7500 - val_loss: 0.7929
Epoch 140/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7576 - loss: 0.7834 - val_accuracy: 0.7083 - val_loss: 0.7897
Epoch 141/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7809 - loss: 0.7909 - val_accuracy: 0.7500 - val_loss: 0.7865
Epoch 142/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.7986 - loss: 0.7983 - val_accuracy: 0.7500 - val_loss: 0.7831
Epoch 143/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7838 - loss: 0.7887 - val_accuracy: 0.7500 - val_loss: 0.7791
Epoch 144/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7865 - loss: 0.7633 - val_accuracy: 0.7083 - val_loss: 0.7758
Epoch 145/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7972 - loss: 0.7853 - val_accuracy: 0.6667 - val_loss: 0.7802
Epoch 146/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.6970 - loss: 0.7898 - val_accuracy: 0.7500 - val_loss: 0.7684
Epoch 147/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step - accuracy: 0.8174 - loss: 0.7632 - val_accuracy: 0.7083 - val_loss: 0.7652
Epoch 148/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.7698 - loss: 0.7761 - val_accuracy: 0.7500 - val_loss: 0.7625
Epoch 149/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.8171 - loss: 0.7748 - val_accuracy: 0.7500 - val_loss: 0.7589
Epoch 150/150
14/14 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 6ms/step - accuracy: 0.8043 - loss: 0.7524 - val_accuracy: 0.7083 - val_loss: 0.7549
8ï¸âƒ£ Evaluate the Model

loss, acc = model.evaluate(X_test, y_test)
print("Test Accuracy:", acc)
2/2 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 22ms/step - accuracy: 0.7931 - loss: 0.7960
Test Accuracy: 0.7833333611488342
9ï¸âƒ£ Test with Known Temperatures (Demo Cell)

test_temps = np.array([-10, 25, 35]).reshape(-1, 1)
test_temps_norm = test_temps / 50.0

pred = model.predict(test_temps_norm)
pred_classes = np.argmax(pred, axis=1)

for t, c in zip(test_temps.flatten(), pred_classes):
    print(f"{t} Â°C â†’ {class_names[c]}")
1/1 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 58ms/step
-10 Â°C â†’ Cold
25 Â°C â†’ Hot
35 Â°C â†’ Hot
unique, counts = np.unique(y, return_counts=True)
dict(zip(unique, counts))
{np.int64(0): np.int64(94),
 np.int64(1): np.int64(107),
 np.int64(2): np.int64(99)}
ğŸ”Ÿ Confidence Interpretation (Very Important)

confidence = np.max(pred, axis=1)

for t, conf in zip(test_temps.flatten(), confidence):
    print(f"Confidence: {conf:.2f}")
Confidence: 0.49
Confidence: 0.48
Confidence: 0.47
pred = model.predict(test_temps_norm)
pred_class = np.argmax(pred, axis=1)
confidence = np.max(pred, axis=1)

for t, c, conf in zip(test_temps.flatten(), pred_class, confidence):
    if conf < 0.7:
        print(f"{t} Â°C â†’ Uncertain")
    else:
        print(f"{t} Â°C â†’ {class_names[c]} ({conf:.2f})")
1/1 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 34ms/step
15 Â°C â†’ Uncertain
25 Â°C â†’ Uncertain
35 Â°C â†’ Uncertain
1ï¸âƒ£1ï¸âƒ£ Convert to TensorFlow Lite (For Embedded)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

tflite_model = converter.convert()

with open("dht22_temp_classifier.tflite", "wb") as f:
    f.write(tflite_model)

print("TFLite model size:", len(tflite_model), "bytes")
Saved artifact at '/tmp/tmprcj_78lp'. The following endpoints are available:

* Endpoint 'serve'
  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1), dtype=tf.float32, name='keras_tensor_4')
Output Type:
  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)
Captures:
  135739290735760: TensorSpec(shape=(), dtype=tf.resource, name=None)
  135739290735376: TensorSpec(shape=(), dtype=tf.resource, name=None)
  135739290734032: TensorSpec(shape=(), dtype=tf.resource, name=None)
  135739290738640: TensorSpec(shape=(), dtype=tf.resource, name=None)
  135739290742096: TensorSpec(shape=(), dtype=tf.resource, name=None)
  135739290745168: TensorSpec(shape=(), dtype=tf.resource, name=None)
TFLite model size: 2900 bytes
